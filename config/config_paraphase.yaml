data:
  train_path: filelist/review_train_data_translated.json
  max_length: 280

dataset_type: paraphase_json


training_args:
  bf16: True
  num_train_epochs: 10
  logging_steps: 100
  eval_steps: 200
  save_steps: 2000
  gradient_accumulation_steps: 1
  per_device_train_batch_size: 16
  warmup_steps: 5
  deepspeed: 'config/ds_b16_config.json' # need to run using deepspeed

generate:
  generate_preset: greedy

model_name: facebook/m2m100_418M
tokenizer_name: facebook/m2m100_418M

lr: 5e-5
