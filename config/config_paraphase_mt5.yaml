data:
  train_path: filelist/review_train_data_translated.json
  max_length: 280

dataset_type: paraphase_json


training_args:
  bf16: True
  num_train_epochs: 10
  logging_steps: 100
  eval_steps: 200
  save_steps: 2000
  gradient_accumulation_steps: 1
  per_device_train_batch_size: 8
  warmup_steps: 5
  # deepspeed: 'config/ds_b16_config.json' # need to run using deepspeed

generate:
  generate_preset: greedy
  config:
    max_length: 200

model_name: google/mt5-base
tokenizer_name: google/mt5-base

lr: 5e-5
